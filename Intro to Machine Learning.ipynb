{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "<div style=\"border:solid green 2px; padding: 20px\">\n    \n<b>Hello, Amanda!</b> We're glad to see you in code-reviewer territory. You've done a great job on the project, but let's get to know each other and make it even better! We have our own atmosphere here and a few rules:\n\n\n1. I work as a code reviewer, and my main goal is not to point out your mistakes, but to share my experience and help you become a data analyst.\n2. We speak on a first-come-first-served basis.\n3. if you want to write or ask a question, don't be shy. Just choose your color for your comment.  \n4. this is a training project, you don't have to be afraid of making a mistake.  \n5. You have an unlimited number of attempts to pass the project.  \n6. Let's Go!\n\n\n---\nI'll be color-coding comments, please don't delete them:\n\n<div class=\"alert alert-block alert-danger\">\u270d\n    \n\n__Reviewer's comment \u21161__\n\nNeeds fixing. The block requires some corrections. Work can't be accepted with the red comments.\n</div>\n    \n---\n\n<div class=\"alert alert-block alert-warning\">\ud83d\udcdd\n    \n\n__Reviewer's comment \u21161__\n\n\nRemarks. Some recommendations.\n</div>\n\n---\n\n<div class=\"alert alert-block alert-success\">\u2714\ufe0f\n    \n\n__Reviewer's comment \u21161__\n\nSuccess. Everything is done succesfully.\n</div>\n    \n---\n    \nI suggest that we work on the project in dialogue: if you change something in the project or respond to my comments, write about it. It will be easier for me to track changes if you highlight your comments:   \n    \n<div class=\"alert alert-info\"> <b>Student \u0441omments:</b> Student answer..</div>\n    \nAll this will help to make the recheck of your project faster. If you have any questions about my comments, let me know, we'll figure it out together :)   \n    \n---"}, {"cell_type": "markdown", "metadata": {}, "source": "# Plan Recommendation Model for Megaline Subscribers\n\n## Description:\nThis project focuses on building a machine learning model to recommend updated plans for Megaline subscribers based on their usage patterns. The goal is to analyze customer behavior and create a classification model that predicts whether a user should switch to the \"Smart\" or \"Ultra\" plan.\n\n## Objective:\nDevelop a machine learning model with the highest possible accuracy to classify subscribers into one of two plans.\nEnsure the model meets or exceeds the required accuracy threshold of 0.75 on the test dataset.\n\n## Data Source:\nThe dataset users_behavior.csv includes monthly usage behavior for each subscriber, such as:\n\ncalls: Number of calls made.\nminutes: Total call duration in minutes.\nmessages: Number of text messages sent.\nmb_used: Internet traffic used in megabytes.\nis_ultra: Current plan (Ultra = 1, Smart = 0).\n\n## Approach:\n1. Data Preparation:\nLoad and inspect the dataset to understand its structure and content.\nSplit the dataset into training, validation, and test subsets.\n2. Model Development:\nTrain various machine learning models with different hyperparameters.\nCompare models based on validation accuracy to select the best-performing one.\n3. Model Evaluation:\nEvaluate the chosen model's performance on the test set.\nConduct a sanity check to ensure the model behaves logically and reliably.\n\n## Tools:\nLibraries: pandas, scikit-learn, and matplotlib.\nMachine Learning Models: Decision Tree, Random Forest, Logistic Regression, and others as needed.\n\n## Deliverables:\nA trained classification model that meets the accuracy requirement.\nAnalysis of different models and their hyperparameters.\nInsights and recommendations based on model performance.\nThis project will help Megaline improve customer satisfaction by identifying and recommending the most suitable plan for their subscribers based on their monthly usage behavior."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\u2714\ufe0f\n    \n\n__Reviewer's comment \u21161__\n\nAn excellent practice is to describe the goal and main steps in your own words (a skill that will help a lot on a final project). "}, {"cell_type": "code", "execution_count": 1, "metadata": {"trusted": false}, "outputs": [], "source": "import pandas as pd\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.metrics import accuracy_score"}, {"cell_type": "code", "execution_count": 2, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "   calls  minutes  messages   mb_used  is_ultra\n0   40.0   311.90      83.0  19915.42         0\n1   85.0   516.75      56.0  22696.96         0\n2   77.0   467.66      86.0  21060.45         0\n3  106.0   745.53      81.0   8437.39         1\n4   66.0   418.74       1.0  14502.75         0\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3214 entries, 0 to 3213\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   calls     3214 non-null   float64\n 1   minutes   3214 non-null   float64\n 2   messages  3214 non-null   float64\n 3   mb_used   3214 non-null   float64\n 4   is_ultra  3214 non-null   int64  \ndtypes: float64(4), int64(1)\nmemory usage: 125.7 KB\n\nMissing Values:\ncalls       0\nminutes     0\nmessages    0\nmb_used     0\nis_ultra    0\ndtype: int64\n\nNumber of Duplicate Rows: 0\n"}], "source": "# Load datasets\n\ndf = pd.read_csv('/datasets/users_behavior.csv')\n\n# Preview the first few rows\nprint(df.head())\n\n# Check dataset structure and basic info\ndf.info()\n\n# Check for missing values and duplicates\nprint(\"\\nMissing Values:\")\nprint(df.isnull().sum())\n\nprint(\"\\nNumber of Duplicate Rows:\", df.duplicated().sum())"}, {"cell_type": "markdown", "metadata": {}, "source": "# Dataset Overview:\nThe dataset has 5 columns:<br>\ncalls: Number of calls (float).<br>\nminutes: Total call duration in minutes (float).<br>\nmessages: Number of text messages (float).<br>\nmb_used: Internet traffic used in MB (float).<br>\nis_ultra: Target variable indicating the plan (0 for Smart and 1 for Ultra) (integer).<br>\nTotal rows: 3214.<br>\nNo missing values or duplicate rows are present, so no cleaning is necessary.<br>\nThe target variable is_ultra is already in the appropriate format (integer).<br>\nFeatures such as calls, minutes, messages, and mb_used are all numeric (float64), making them ready for modeling.<br>"}, {"cell_type": "code", "execution_count": 3, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Training set size: (1928, 4) (1928,)\nValidation set size: (643, 4) (643,)\nTest set size: (643, 4) (643,)\n"}], "source": "# Define features and target\nfeatures = df.drop(['is_ultra'], axis=1)\ntarget = df['is_ultra']\n\n# Split the dataset into training (60%), validation (20%), and test (20%) sets\nfeatures_train, features_temp, target_train, target_temp = train_test_split(\n    features, target, test_size=0.4, random_state=12345)  # Initial split: 60% train, 40% temp\n\nfeatures_valid, features_test, target_valid, target_test = train_test_split(\n    features_temp, target_temp, test_size=0.5, random_state=12345)  # Split temp into 20% valid, 20% test\n\n# Display the shapes of the resulting subsets\nprint(\"Training set size:\", features_train.shape, target_train.shape)\nprint(\"Validation set size:\", features_valid.shape, target_valid.shape)\nprint(\"Test set size:\", features_test.shape, target_test.shape)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\u2714\ufe0f\n    \n\n__Reviewer's comment \u21161__\n\n\n\n1. It is good here, random_state is fixed. We have ensured reproducibility of the results of splitting the sample into training (training) / test / validation samples, so the subsamples will be identical in all subsequent runs of our code.\n    \n2. Fraction of train/valid/test sizes 3:1:1 is good."}, {"cell_type": "code", "execution_count": 4, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Validation Set Accuracy: 0.713841368584759\n"}], "source": "# Train a Decision Tree Classifier on the training set\nmodel = DecisionTreeClassifier(random_state=12345)\nmodel.fit(features_train, target_train)\n\n# Make predictions on the validation set\npredictions_valid = model.predict(features_valid)\n\n# Calculate and print accuracy on the validation set\naccuracy = accuracy_score(target_valid, predictions_valid)\nprint(\"Validation Set Accuracy:\", accuracy)"}, {"cell_type": "markdown", "metadata": {}, "source": "# Result Analysis\nThe Decision Tree Classifier achieved an accuracy of 71.38% on the validation set. This result is below the required threshold of 75%, indicating that the model's predictions can be improved."}, {"cell_type": "code", "execution_count": 5, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "max_depth=1, Validation Accuracy: 0.7542768273716952\nmax_depth=2, Validation Accuracy: 0.7822706065318819\nmax_depth=3, Validation Accuracy: 0.7853810264385692\nmax_depth=4, Validation Accuracy: 0.7791601866251944\nmax_depth=5, Validation Accuracy: 0.7791601866251944\nmax_depth=6, Validation Accuracy: 0.7838258164852255\nmax_depth=7, Validation Accuracy: 0.7822706065318819\nmax_depth=8, Validation Accuracy: 0.7791601866251944\nmax_depth=9, Validation Accuracy: 0.7822706065318819\nmax_depth=10, Validation Accuracy: 0.7744945567651633\n\nBest max_depth: 3, Best Validation Accuracy: 0.7853810264385692\n"}], "source": "# Tune the 'max_depth' hyperparameter for the Decision Tree\nbest_accuracy = 0\nbest_depth = 0\n\nfor depth in range(1, 11):  # Try depths from 1 to 10\n    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n    model.fit(features_train, target_train)\n    predictions_valid = model.predict(features_valid)\n    accuracy = accuracy_score(target_valid, predictions_valid)\n    print(f\"max_depth={depth}, Validation Accuracy: {accuracy}\")\n    \n    # Track the best depth and accuracy\n    if accuracy > best_accuracy:\n        best_accuracy = accuracy\n        best_depth = depth\n\nprint(f\"\\nBest max_depth: {best_depth}, Best Validation Accuracy: {best_accuracy}\")"}, {"cell_type": "markdown", "metadata": {}, "source": "# Analysis of Results\nOptimal Depth:\n\nThe best validation accuracy was achieved with max_depth=3, resulting in an accuracy of 78.54%.\nPerformance Trend:\n\nAccuracy improves initially as the depth increases, peaking at max_depth=3.\nBeyond max_depth=3, the model starts overfitting slightly, as accuracy either stagnates or decreases."}, {"cell_type": "code", "execution_count": 6, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "    Feature  Importance\n3   mb_used    0.513756\n1   minutes    0.274619\n2  messages    0.193568\n0     calls    0.018057\n"}], "source": "# Train the Decision Tree with the best max_depth\nbest_model = DecisionTreeClassifier(random_state=12345, max_depth=3)\nbest_model.fit(features_train, target_train)\n\n# Extract feature importances\nimportances = best_model.feature_importances_\n\n# Create a DataFrame to display the feature importances\nfeature_importance = pd.DataFrame({\n    'Feature': features_train.columns,\n    'Importance': importances\n}).sort_values(by='Importance', ascending=False)\n\n# Display feature importance\nprint(feature_importance)"}, {"cell_type": "markdown", "metadata": {}, "source": "# Feature Importance Analysis\nThe Decision Tree model identifies the following features as most influential for predicting whether a subscriber should switch to the \"Ultra\" plan:\n\nmb_used (Internet usage in MB):\n\nImportance: 51.38%\nInternet usage is the most significant factor influencing the prediction. Users with higher internet usage likely need the \"Ultra\" plan.\nminutes (Total call duration in minutes):\n\nImportance: 27.46%\nThe total time spent on calls also significantly contributes to the prediction. Higher call durations may indicate a preference for a more comprehensive plan like \"Ultra.\"\nmessages (Number of text messages):\n\nImportance: 19.36%\nText messaging usage is a moderately important factor. Users sending more messages may benefit from the \"Ultra\" plan.\ncalls (Number of calls):\n\nImportance: 1.81%\nThe number of calls made is the least significant factor. While it provides some information, it doesn't heavily influence the prediction.\n\n\nFeature Importance Analysis\nThe Decision Tree model identifies the following features as most influential for predicting whether a subscriber should switch to the \"Ultra\" plan:\n\nmb_used (Internet usage in MB):\n\nImportance: 51.38%\nInternet usage is the most significant factor influencing the prediction. Users with higher internet usage likely need the \"Ultra\" plan.\nminutes (Total call duration in minutes):\n\nImportance: 27.46%\nThe total time spent on calls also significantly contributes to the prediction. Higher call durations may indicate a preference for a more comprehensive plan like \"Ultra.\"\nmessages (Number of text messages):\n\nImportance: 19.36%\nText messaging usage is a moderately important factor. Users sending more messages may benefit from the \"Ultra\" plan.\ncalls (Number of calls):\n\nImportance: 1.81%\nThe number of calls made is the least significant factor. While it provides some information, it doesn't heavily influence the prediction.\n\n# Key Insights\nThe model relies heavily on internet usage (mb_used) and call duration (minutes) for making decisions.\nText messages (messages) play a secondary role.\nThe number of calls (calls) has minimal impact, suggesting it may not vary significantly between the two plans or is not as indicative of plan suitability."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\u2714\ufe0f\n    \n\n__Reviewer's comment \u21161__\n\n\nOtherwise it's great\ud83d\ude0a. Your project is begging for github =)   \n    \nCongratulations on the successful completion of the project \ud83d\ude0a\ud83d\udc4d\nAnd I wish you success in new works \ud83d\ude0a"}], "metadata": {"ExecuteTimeLog": [{"duration": 156, "start_time": "2024-12-01T18:17:18.507Z"}, {"duration": 325, "start_time": "2024-12-01T18:17:39.136Z"}, {"duration": 394, "start_time": "2024-12-01T18:17:39.872Z"}, {"duration": 14, "start_time": "2024-12-01T18:18:47.082Z"}, {"duration": 16, "start_time": "2024-12-01T18:27:36.407Z"}, {"duration": 17, "start_time": "2024-12-01T18:28:14.661Z"}, {"duration": 424, "start_time": "2024-12-01T18:30:54.951Z"}, {"duration": 18, "start_time": "2024-12-01T18:30:55.516Z"}, {"duration": 8, "start_time": "2024-12-01T18:31:15.818Z"}, {"duration": 102, "start_time": "2024-12-01T18:33:42.123Z"}, {"duration": 18, "start_time": "2024-12-01T18:33:44.456Z"}, {"duration": 8, "start_time": "2024-12-01T18:33:47.078Z"}, {"duration": 13, "start_time": "2024-12-01T18:34:01.627Z"}, {"duration": 56, "start_time": "2024-12-01T18:36:18.101Z"}, {"duration": 9, "start_time": "2024-12-01T18:38:02.444Z"}, {"duration": 757, "start_time": "2024-12-01T20:35:31.879Z"}, {"duration": 24, "start_time": "2024-12-01T20:35:32.638Z"}, {"duration": 8, "start_time": "2024-12-01T20:35:32.664Z"}, {"duration": 15, "start_time": "2024-12-01T20:35:32.675Z"}, {"duration": 73, "start_time": "2024-12-01T20:35:32.693Z"}, {"duration": 10, "start_time": "2024-12-01T20:35:32.768Z"}, {"duration": 218, "start_time": "2024-12-01T20:37:38.947Z"}, {"duration": 53, "start_time": "2024-12-01T20:37:56.937Z"}], "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.19"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": true, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": true}}, "nbformat": 4, "nbformat_minor": 2}